{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawel/anaconda3/envs/gt/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.21.6\n",
      "Rdkit version: 2022.09.5\n",
      "Torch version: 1.13.1\n",
      "TorchMetrics version: 0.11.4\n"
     ]
    }
   ],
   "source": [
    "# Standard\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import RDLogger\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "\n",
    "# GT-PyG\n",
    "import gt_pyg\n",
    "from gt_pyg.data.utils import (\n",
    "    get_tensor_data, \n",
    "    get_node_dim, \n",
    "    get_edge_dim, \n",
    "    get_train_valid_test_data\n",
    ")\n",
    "from gt_pyg.nn.model import GraphTransformerNet\n",
    "\n",
    "\n",
    "# Turn off majority of RDKit warnings\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "\n",
    "# Set a random seed for a reproducibility purposes\n",
    "torch.manual_seed(192837465)\n",
    "\n",
    "# Setup the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Log the used versions of RDkit and torch\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Rdkit version: {rdkit.__version__}')\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'TorchMetrics version: {torchmetrics.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ADME@TDC data\n",
    "\n",
    "**Note**: To use the code below, make sure that the chosen endpoint is a regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available endpoints:\n",
      "\n",
      "1. caco2_wang\n",
      "2. hia_hou\n",
      "3. pgp_broccatelli\n",
      "4. bioavailability_ma\n",
      "5. lipophilicity_astrazeneca\n",
      "6. solubility_aqsoldb\n",
      "7. bbb_martins\n",
      "8. ppbr_az\n",
      "9. vdss_lombardo\n",
      "10. cyp2d6_veith\n",
      "11. cyp3a4_veith\n",
      "12. cyp2c9_veith\n",
      "13. cyp2d6_substrate_carbonmangels\n",
      "14. cyp3a4_substrate_carbonmangels\n",
      "15. cyp2c9_substrate_carbonmangels\n",
      "16. half_life_obach\n",
      "17. clearance_microsome_az\n",
      "18. clearance_hepatocyte_az\n",
      "19. herg\n",
      "20. ames\n",
      "21. dili\n",
      "22. ld50_zhu\n"
     ]
    }
   ],
   "source": [
    "from tdc import utils\n",
    "names = utils.retrieve_benchmark_names('ADMET_Group')\n",
    "output = \"\\n\".join([f\"{index}. {name}\" for index, name in enumerate(names, start=1)])\n",
    "print(\"Available endpoints:\\n\\n\" + output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression endpoints with MAE metric:\n",
    "1. caco2_wang (Best: 0.285 ± 0.005)\n",
    "2. lipophilicity_astrazeneca (Best: 0.535 ± 0.012)\n",
    "3. solubility_aqsoldb (Best: 0.776 ± 0.008)\n",
    "4. ppbr_az (Best: 9.185 ± 0.000)\n",
    "5. ld50_zhu (Best: 0.588 ± 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1130\n",
      "Number of validation examples: 161\n",
      "Number of test examples: 323\n"
     ]
    }
   ],
   "source": [
    "PE_DIM = 6\n",
    "(tr, va, te) = get_train_valid_test_data('ppbr_az', min_num_atoms=0)\n",
    "tr_dataset = get_tensor_data(tr.Drug.to_list(), tr.Y.to_list(), pe_dim=PE_DIM, gnn=False)\n",
    "va_dataset = get_tensor_data(va.Drug.to_list(), va.Y.to_list(), pe_dim=PE_DIM, gnn=False)\n",
    "te_dataset = get_tensor_data(te.Drug.to_list(), te.Y.to_list(), pe_dim=PE_DIM, gnn=False)\n",
    "NODE_DIM = get_node_dim()\n",
    "EDGE_DIM = get_edge_dim()\n",
    "\n",
    "print(f'Number of training examples: {len(tr_dataset)}')\n",
    "print(f'Number of validation examples: {len(va_dataset)}')\n",
    "print(f'Number of test examples: {len(te_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(tr_dataset, batch_size=64)\n",
    "val_loader = DataLoader(va_dataset, batch_size=512)\n",
    "test_loader = DataLoader(te_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and eval the GT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loss_func):\n",
    "    model.train()\n",
    "    train_mae = MeanAbsoluteError()\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # randomly flip sign of eigenvectors\n",
    "        batch_pe = data.pe * (2 * torch.randint(low=0, high=2, size=(1, PE_DIM)).float() - 1.0)\n",
    "        (out,_) = model(data.x, data.edge_index, data.edge_attr, batch_pe, data.batch, zero_var=False)\n",
    "        loss = loss_func(out.squeeze(), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_mae.update(out.squeeze(), data.y)\n",
    "\n",
    "    return train_mae.compute()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    test_mae = MeanAbsoluteError()\n",
    "\n",
    "    total_error = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        # randomly flip sign of eigenvectors\n",
    "        batch_pe = data.pe * (2 * torch.randint(low=0, high=2, size=(1, PE_DIM)).float() - 1.0)\n",
    "        (out,_) = model(data.x, data.edge_index, data.edge_attr, batch_pe, data.batch)\n",
    "        \n",
    "        test_mae.update(out.squeeze(), data.y)\n",
    "        \n",
    "    return test_mae.compute()\n",
    "\n",
    "train_loss = nn.L1Loss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Graph Transformer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphTransformerNet(\n",
      "  (node_emb): Linear(in_features=76, out_features=128, bias=False)\n",
      "  (edge_emb): Linear(in_features=10, out_features=128, bias=False)\n",
      "  (pe_emb): Linear(in_features=6, out_features=128, bias=False)\n",
      "  (gt_layers): ModuleList(\n",
      "    (0): GTConv(128, 128, heads=8, aggrs: sum, qkv_bias: False, gate: True)\n",
      "    (1): GTConv(128, 128, heads=8, aggrs: sum, qkv_bias: False, gate: True)\n",
      "    (2): GTConv(128, 128, heads=8, aggrs: sum, qkv_bias: False, gate: True)\n",
      "    (3): GTConv(128, 128, heads=8, aggrs: sum, qkv_bias: False, gate: True)\n",
      "  )\n",
      "  (global_pool): MultiAggregation([\n",
      "    SumAggregation(),\n",
      "  ], mode=cat)\n",
      "  (mu_mlp): MLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (log_var_mlp): MLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of params: 840 k\n",
      "Epoch: 01, Loss: 70.0617, Val: 50.3657, Test: 47.9393\n",
      "Epoch: 02, Loss: 44.2053, Val: 48.4013, Test: 44.3330\n",
      "Epoch: 03, Loss: 31.7299, Val: 28.7067, Test: 27.6935\n",
      "Epoch: 04, Loss: 23.5238, Val: 32.7482, Test: 32.5446\n",
      "Epoch: 05, Loss: 20.3995, Val: 22.8497, Test: 22.2680\n",
      "Epoch: 06, Loss: 19.5830, Val: 24.4021, Test: 24.8836\n",
      "Epoch: 07, Loss: 18.1877, Val: 18.9182, Test: 19.5021\n",
      "Epoch: 08, Loss: 16.9710, Val: 15.7466, Test: 17.6811\n",
      "Epoch: 09, Loss: 16.0680, Val: 15.2489, Test: 16.2252\n",
      "Epoch: 10, Loss: 15.2530, Val: 13.9838, Test: 15.1801\n",
      "Epoch: 11, Loss: 14.8453, Val: 15.9723, Test: 15.8255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4b/hq3_lmzj215_hw29qxb407dc0000gn/T/ipykernel_56850/3523319961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest_set_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mva_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mte_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4b/hq3_lmzj215_hw29qxb407dc0000gn/T/ipykernel_56850/3880932805.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, loss_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gt/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gt/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gt/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m                   \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                   \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                   capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gt/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    230\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gt/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphTransformerNet(node_dim_in=NODE_DIM,\n",
    "                            edge_dim_in=EDGE_DIM,\n",
    "                            pe_in_dim=PE_DIM,\n",
    "                            num_gt_layers=4, \n",
    "                            hidden_dim=128,\n",
    "                            num_heads=8,\n",
    "                            norm='bn',\n",
    "                            gate=True,\n",
    "                            qkv_bias=False,\n",
    "                            gt_aggregators=['sum'],\n",
    "                            aggregators=['sum'],\n",
    "                            dropout=0.1,\n",
    "                            act='relu').to(device)\n",
    "\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    model = torch_geometric.compile(model) \n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "print(model)\n",
    "print(f\"Number of params: {model.num_parameters()//1000} k\")\n",
    "\n",
    "best_epoch = 0\n",
    "best_validation_loss = np.inf\n",
    "test_set_mae = np.inf\n",
    "for epoch in range(1, 51):\n",
    "    tr_loss = train(epoch, loss_func=train_loss)\n",
    "    va_loss = test(val_loader)\n",
    "    te_loss = test(test_loader)\n",
    "    scheduler.step(va_loss)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {tr_loss:.4f}, Val: {va_loss:.4f}, '\n",
    "          f'Test: {te_loss:.4f}')\n",
    "    if va_loss < best_validation_loss:\n",
    "        best_epoch = epoch\n",
    "        best_validation_loss = va_loss\n",
    "        test_set_mae = te_loss\n",
    "        \n",
    "print(\"\\nModel's performance on the test set\\n\"\n",
    "        \"===================================\\n\"\n",
    "        f'MAE={test_set_mae}\\n'\n",
    "        f'Epoch={best_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slighlty optimized Graph Transformer architecture\n",
    "\n",
    "1. `gelu` activation is used instead of `relu`\n",
    "2. Multiaggregator used for global pooling\n",
    "3. Multiaggregator used for message passing\n",
    "\n",
    "Number of params 873k instead of 709k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphTransformerNet(node_dim_in=NODE_DIM,\n",
    "                            edge_dim_in=EDGE_DIM,\n",
    "                            pe_in_dim=PE_DIM,\n",
    "                            num_gt_layers=4, \n",
    "                            hidden_dim=128,\n",
    "                            num_heads=8,\n",
    "                            norm='bn',\n",
    "                            gt_aggregators=['sum', \"mean\"],\n",
    "                            aggregators=['sum','mean','max', 'std'],\n",
    "                            dropout=0.1,\n",
    "                            act='gelu').to(device)\n",
    "\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    model = torch_geometric.compile(model) \n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "print(model)\n",
    "print(f\"Number of params: {model.num_parameters()//1000} k\")\n",
    "\n",
    "\n",
    "best_epoch = 0\n",
    "best_validation_loss = np.inf\n",
    "test_set_mae = np.inf\n",
    "for epoch in range(1, 51):\n",
    "    tr_loss = train(epoch, loss_func=train_loss)\n",
    "    va_loss = test(val_loader)\n",
    "    te_loss = test(test_loader)\n",
    "    scheduler.step(va_loss)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {tr_loss:.4f}, Val: {va_loss:.4f}, '\n",
    "          f'Test: {te_loss:.4f}')\n",
    "    if va_loss < best_validation_loss:\n",
    "        best_epoch = epoch\n",
    "        best_validation_loss = va_loss\n",
    "        test_set_mae = te_loss\n",
    "        \n",
    "print(\"\\nModel's performance on the test set\\n\"\n",
    "        \"===================================\\n\"\n",
    "        f'MAE={test_set_mae}\\n'\n",
    "        f'Epoch={best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

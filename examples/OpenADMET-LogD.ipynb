{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenADMET LogD Training with Graph Transformer\n",
    "This notebook demonstrates how to train a **Graph Transformer** model to predict\n",
    "**LogD** using the [OpenADMET](https://openadmet.ghost.io/openadmet-expansionrx-blind-challenge/)\n",
    "dataset and the `gt-pyg` library.\n",
    "\n",
    "- Graph Transformer in Pytorch Geometric: [gt_pyg](https://github.com/pgniewko/gt-pyg)\n",
    "- `v1.6.0`\n",
    "\n",
    "**Protocol summary:**\n",
    "- 1 endpoint: **LogD** (no log-transform needed)\n",
    "- Loss: **MAE**\n",
    "- 250 epochs, **cosine annealing** LR schedule (no warmup)\n",
    "- Track best MAE on the validation set\n",
    "- Evaluate on the held-out test set (public leaderboard + private split)\n",
    "\n",
    "> **Note:** This is an exemplary training run for demonstration purposes,\n",
    "> not a production-grade model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.metrics import r2_score\n",
    "from copy import deepcopy\n",
    "\n",
    "from gt_pyg.data import get_tensor_data, get_atom_feature_dim, get_bond_feature_dim\n",
    "from gt_pyg.nn import GraphTransformerNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "TRAIN_CSV = \"data/train-set/expansion_log_data_train.csv\"\n",
    "TEST_CSV = \"data/test-set/expansion_data_test_full_lb_flag.csv\"\n",
    "\n",
    "# Model\n",
    "HIDDEN_DIM = 128\n",
    "NUM_GT_LAYERS = 4\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.3\n",
    "GT_AGGREGATORS=[\"sum\", \"mean\"]\n",
    "AGGREGATORS=[\"sum\", \"mean\", \"max\", \"std\"]\n",
    "NORM = \"bn\"\n",
    "ACTIVATION = \"gelu\"\n",
    "GATE = True\n",
    "\n",
    "# Training\n",
    "EPOCHS = 250\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Split Data\n",
    "\n",
    "The training set contains LogD values. Rows with missing LogD are dropped\n",
    "(~5% of data). We perform a random 80/20 train/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total molecules in file: 5326\n",
      "Dropped (missing LogD): 287\n",
      "Final dataset size:     5039\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(TRAIN_CSV)\n",
    "total = len(raw_df)\n",
    "\n",
    "# Keep only SMILES and LogD; drop rows with missing LogD\n",
    "log_train_df = raw_df[[\"SMILES\", \"Molecule Name\", \"LogD\"]].copy()\n",
    "n_missing = log_train_df[\"LogD\"].isna().sum()\n",
    "log_train_df = log_train_df.dropna(subset=[\"LogD\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total molecules in file: {total}\")\n",
    "print(f\"Dropped (missing LogD): {n_missing}\")\n",
    "print(f\"Final dataset size:     {len(log_train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4031, Validation: 1008\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split 80/20\n",
    "df = log_train_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "n_train = int(0.8 * len(df))\n",
    "tr_df = df.iloc[:n_train].copy()\n",
    "va_df = df.iloc[n_train:].copy()\n",
    "\n",
    "print(f\"Train: {len(tr_df)}, Validation: {len(va_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build PyG Datasets and DataLoaders\n",
    "\n",
    "`get_tensor_data` converts SMILES + labels into PyG `Data` objects with\n",
    "atom/bond features and GNM positional encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d0be5a227f418d85d64972b99dcd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data:   0%|          | 0/4031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelgniewek/projects/gt-pyg/gt_pyg/data/utils.py:236: RuntimeWarning: divide by zero encountered in divide\n",
      "  inv_eigenvalues = np.where(np.abs(eigenvalues) > 1e-10, 1.0 / eigenvalues, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f6b918b4744d82adb34890487dc323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data:   0%|          | 0/1008 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train batches: 16, Val batches: 4\n",
      "Node features: 139, Edge features: 39\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(df):\n",
    "    \"\"\"Convert a DataFrame into a list of PyG Data objects.\"\"\"\n",
    "    smiles = df[\"SMILES\"].tolist()\n",
    "    labels = df[\"LogD\"].tolist()\n",
    "    return get_tensor_data(smiles, labels)\n",
    "\n",
    "print(\"Building training set...\")\n",
    "tr_dataset = build_dataset(tr_df)\n",
    "print(\"Building validation set...\")\n",
    "va_dataset = build_dataset(va_df)\n",
    "\n",
    "tr_loader = DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "va_loader = DataLoader(va_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(tr_loader)}, Val batches: {len(va_loader)}\")\n",
    "print(f\"Node features: {tr_dataset[0].x.shape[1]}, Edge features: {tr_dataset[0].edge_attr.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model, Optimizer, and Scheduler\n",
    "\n",
    "We use `GraphTransformerNet` with a single output. The LR follows a **cosine\n",
    "annealing** schedule from `LR` down to 0 over 250 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 2,797,634\n"
     ]
    }
   ],
   "source": [
    "node_dim = get_atom_feature_dim()\n",
    "edge_dim = get_bond_feature_dim()\n",
    "\n",
    "model = GraphTransformerNet(\n",
    "    node_dim_in=node_dim,\n",
    "    edge_dim_in=edge_dim,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_gt_layers=NUM_GT_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    norm=NORM,\n",
    "    gt_aggregators=GT_AGGREGATORS,\n",
    "    aggregators=AGGREGATORS,\n",
    "    act=ACTIVATION,\n",
    "    gate=GATE,\n",
    "    num_tasks=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Parameters: {model.num_parameters():,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Evaluation Functions\n",
    "\n",
    "The loss is **MAE** computed over all samples.\n",
    "\n",
    "Evaluation computes **MAE, RAE, R², Spearman $\\rho$, Kendall $\\tau$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss(pred, target):\n",
    "    \"\"\"MAE loss over all samples.\"\"\"\n",
    "    return (pred - target).abs().mean()\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    \"\"\"Run one training epoch. Returns average loss.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred, _ = model(\n",
    "            x=batch.x,\n",
    "            edge_index=batch.edge_index,\n",
    "            edge_attr=batch.edge_attr,\n",
    "            batch=batch.batch,\n",
    "        )\n",
    "\n",
    "        loss = mae_loss(pred, batch.y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(n_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate model. Returns dict with MAE, RAE, R2, Spearman, Kendall.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred, _ = model(\n",
    "            x=batch.x,\n",
    "            edge_index=batch.edge_index,\n",
    "            edge_attr=batch.edge_attr,\n",
    "            batch=batch.batch,\n",
    "        )\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_targets.append(batch.y.cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds, dim=0).numpy().ravel()\n",
    "    targets = torch.cat(all_targets, dim=0).numpy().ravel()\n",
    "\n",
    "    mae = float(np.mean(np.abs(targets - preds)))\n",
    "    denom = np.mean(np.abs(targets - np.mean(targets)))\n",
    "    rae = float(mae / denom) if denom > 0 else np.nan\n",
    "    r2 = float(r2_score(targets, preds)) if np.std(targets) > 0 else np.nan\n",
    "\n",
    "    if np.std(preds) < 1e-4:\n",
    "        spr, ktau = np.nan, np.nan\n",
    "    else:\n",
    "        spr = float(spearmanr(targets, preds)[0])\n",
    "        ktau = float(kendalltau(targets, preds)[0])\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RAE\": rae,\n",
    "        \"R2\": r2,\n",
    "        \"Spearman R\": spr,\n",
    "        \"Kendall's Tau\": ktau,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "We train for 250 epochs, tracking the **best MAE** on the validation set.\n",
    "The best model weights are stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/250 | Loss: 2.1079 | Train MAE=1.055 RAE=1.120 R2=-0.189 rho=0.325 tau=0.225 | Val MAE=1.005 RAE=1.068 R2=-0.135 rho=0.356 tau=0.246 | LR: 1.00e-03\n",
      "Epoch  10/250 | Loss: 0.9396 | Train MAE=1.004 RAE=1.066 R2=-0.082 rho=0.628 tau=0.458 | Val MAE=0.963 RAE=1.023 R2=-0.032 rho=0.638 tau=0.466 | LR: 9.96e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m KT_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKendall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Tau\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m     val_m \u001b[38;5;241m=\u001b[39m evaluate(model, va_loader, DEVICE)\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m pred, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m mae_loss(pred, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/projects/gt-pyg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/gt-pyg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/gt-pyg/gt_pyg/nn/model.py:268\u001b[0m, in \u001b[0;36mGraphTransformerNet.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch, zero_var)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_dim_in was set in __init__, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is None in forward().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         )\n\u001b[0;32m--> 268\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/gt-pyg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/gt-pyg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/gt-pyg/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_mae = float(\"inf\")\n",
    "best_model_state = None\n",
    "best_epoch = -1\n",
    "\n",
    "history = {\n",
    "    \"epoch\": [], \"train_loss\": [], \"lr\": [],\n",
    "    \"val_mae\": [], \"val_rae\": [], \"val_r2\": [],\n",
    "    \"val_spearman\": [], \"val_kendall\": [],\n",
    "    \"train_mae\": [], \"train_rae\": [], \"train_r2\": [],\n",
    "    \"train_spearman\": [], \"train_kendall\": [],\n",
    "    \"logged_epoch\": [],\n",
    "}\n",
    "\n",
    "KT_KEY = \"Kendall's Tau\"\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, tr_loader, optimizer, DEVICE)\n",
    "    scheduler.step()\n",
    "\n",
    "    val_m = evaluate(model, va_loader, DEVICE)\n",
    "    val_mae = val_m[\"MAE\"]\n",
    "    lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"lr\"].append(lr_now)\n",
    "    history[\"val_mae\"].append(val_mae)\n",
    "    history[\"val_rae\"].append(val_m[\"RAE\"])\n",
    "    history[\"val_r2\"].append(val_m[\"R2\"])\n",
    "    history[\"val_spearman\"].append(val_m[\"Spearman R\"])\n",
    "    history[\"val_kendall\"].append(val_m[KT_KEY])\n",
    "\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_epoch = epoch\n",
    "        best_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        tr_m = evaluate(model, tr_loader, DEVICE)\n",
    "\n",
    "        history[\"logged_epoch\"].append(epoch)\n",
    "        history[\"train_mae\"].append(tr_m[\"MAE\"])\n",
    "        history[\"train_rae\"].append(tr_m[\"RAE\"])\n",
    "        history[\"train_r2\"].append(tr_m[\"R2\"])\n",
    "        history[\"train_spearman\"].append(tr_m[\"Spearman R\"])\n",
    "        history[\"train_kendall\"].append(tr_m[KT_KEY])\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:3d}/{EPOCHS} | \"\n",
    "            f\"Loss: {train_loss:.4f} | \"\n",
    "            f\"Train MAE={tr_m['MAE']:.3f} RAE={tr_m['RAE']:.3f} \"\n",
    "            f\"R2={tr_m['R2']:.3f} rho={tr_m['Spearman R']:.3f} \"\n",
    "            f\"tau={tr_m[KT_KEY]:.3f} | \"\n",
    "            f\"Val MAE={val_m['MAE']:.3f} RAE={val_m['RAE']:.3f} \"\n",
    "            f\"R2={val_m['R2']:.3f} rho={val_m['Spearman R']:.3f} \"\n",
    "            f\"tau={val_m[KT_KEY]:.3f} | \"\n",
    "            f\"LR: {lr_now:.2e}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\nBest val MAE: {best_val_mae:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Restore Best Model and Print Final Stats\n",
    "\n",
    "Load the best checkpoint (by validation MAE) and report LogD metrics on\n",
    "both train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "tr_metrics = evaluate(model, tr_loader, DEVICE)\n",
    "va_metrics = evaluate(model, va_loader, DEVICE)\n",
    "\n",
    "KT_KEY = \"Kendall's Tau\"\n",
    "\n",
    "header = (\n",
    "    f\"{'Split':<10} \"\n",
    "    f\"{'MAE':>10} {'RAE':>10} {'R2':>10} \"\n",
    "    f\"{'Spearman':>10} {'Kendall':>10}\"\n",
    ")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for name, m in [(\"Train\", tr_metrics), (\"Val\", va_metrics)]:\n",
    "    print(\n",
    "        f\"{name:<10} \"\n",
    "        f\"{m['MAE']:>10.4f} {m['RAE']:>10.4f} {m['R2']:>10.4f} \"\n",
    "        f\"{m['Spearman R']:>10.4f} {m[KT_KEY]:>10.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ---- (0,0) Loss curves (LOG SCALE) ----\n",
    "ax = axes[0, 0]\n",
    "ax.semilogy(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\", alpha=0.8)\n",
    "# Compute val loss from val_mae as proxy (we don't track val loss separately)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss (log scale)\")\n",
    "ax.set_title(\"Training Loss\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- (0,1) RAE (capped at 1.0) ----\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history[\"epoch\"], history[\"val_rae\"], \"b-\", alpha=0.8, label=\"Val RAE\")\n",
    "if history[\"logged_epoch\"]:\n",
    "    ax.plot(history[\"logged_epoch\"], history[\"train_rae\"], \"b--\", alpha=0.5, label=\"Train RAE\")\n",
    "best_rae = min(history[\"val_rae\"])\n",
    "ax.axhline(best_rae, color=\"r\", linestyle=\"--\", alpha=0.5, label=f\"Best Val: {best_rae:.3f}\")\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"RAE\")\n",
    "ax.set_title(\"RAE\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- (1,0) R² (capped at 1.0) ----\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history[\"epoch\"], history[\"val_r2\"], \"g-\", alpha=0.8, label=\"Val R²\")\n",
    "if history[\"logged_epoch\"]:\n",
    "    ax.plot(history[\"logged_epoch\"], history[\"train_r2\"], \"g--\", alpha=0.5, label=\"Train R²\")\n",
    "best_r2 = max(history[\"val_r2\"])\n",
    "ax.axhline(best_r2, color=\"r\", linestyle=\"--\", alpha=0.5, label=f\"Best Val: {best_r2:.3f}\")\n",
    "ax.set_ylim(-0.1, 1.0)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"R²\")\n",
    "ax.set_title(\"R²\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- (1,1) Kendall τ ----\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history[\"epoch\"], history[\"val_kendall\"], \"m-\", alpha=0.8, label=\"Val τ\")\n",
    "if history[\"logged_epoch\"]:\n",
    "    ax.plot(history[\"logged_epoch\"], history[\"train_kendall\"], \"m--\", alpha=0.5, label=\"Train τ\")\n",
    "best_tau = max(history[\"val_kendall\"])\n",
    "ax.axhline(best_tau, color=\"r\", linestyle=\"--\", alpha=0.5, label=f\"Best Val: {best_tau:.3f}\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Kendall τ\")\n",
    "ax.set_title(\"Kendall τ\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Validation: MAE and R² side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "bar_data = pd.DataFrame({\n",
    "    \"Split\": [\"Train\", \"Val\"],\n",
    "    \"MAE\": [tr_metrics[\"MAE\"], va_metrics[\"MAE\"]],\n",
    "    \"R2\": [tr_metrics[\"R2\"], va_metrics[\"R2\"]],\n",
    "})\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.barplot(x=\"Split\", y=\"MAE\", data=bar_data, ax=ax1, palette=\"muted\")\n",
    "ax1.set_title(\"LogD — MAE\")\n",
    "ax1.set_ylabel(\"MAE\")\n",
    "\n",
    "sns.barplot(x=\"Split\", y=\"R2\", data=bar_data, ax=ax2, palette=\"muted\")\n",
    "ax2.set_title(\"LogD — R²\")\n",
    "ax2.set_ylabel(\"R²\")\n",
    "ax2.set_ylim(0, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Set Prediction & Submission\n",
    "\n",
    "Generate predictions on the held-out test set and save as `submission.csv`.\n",
    "LogD requires no inverse transform — predictions are used directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load test set ---\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "smiles_test = test_df[\"SMILES\"].tolist()\n",
    "\n",
    "# --- Build PyG dataset (inference — no labels) ---\n",
    "print(\"\\nFeaturising test SMILES...\")\n",
    "test_dataset = get_tensor_data(smiles_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Run inference ---\n",
    "model.eval()\n",
    "test_preds_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        pred, _ = model(\n",
    "            x=batch.x,\n",
    "            edge_index=batch.edge_index,\n",
    "            edge_attr=batch.edge_attr,\n",
    "            batch=batch.batch,\n",
    "        )\n",
    "        test_preds_list.append(pred.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds_list, axis=0).ravel()  # [N]\n",
    "print(f\"Predictions shape: {test_preds.shape}\")\n",
    "\n",
    "# --- Save submission ---\n",
    "sub_df = test_df[[\"Molecule Name\", \"SMILES\"]].copy()\n",
    "sub_df[\"LogD\"] = test_preds\n",
    "\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"\\nSaved submission.csv with {len(sub_df)} rows\")\n",
    "print(f\"Columns: {sub_df.columns.tolist()}\\n\")\n",
    "\n",
    "print(\"Head:\")\n",
    "print(sub_df.head().to_string())\n",
    "\n",
    "print(f\"\\nLogD prediction range: \"\n",
    "      f\"min={test_preds.min():.4f}  max={test_preds.max():.4f}  \"\n",
    "      f\"mean={test_preds.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Set Evaluation — Leaderboard vs Private\n",
    "\n",
    "Evaluate the submission against the full test-set ground truth, split three ways:\n",
    "**LB** (public leaderboard), **Private**, and **All**.\n",
    "\n",
    "We report LogD metrics with bootstrap confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Evaluation helpers (simplified for single LogD endpoint)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def bootstrap_sampling(size, n_samples, seed=0):\n",
    "    \"\"\"Generate bootstrap sample indices.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.choice(size, size=(n_samples, size), replace=True)\n",
    "\n",
    "\n",
    "def metrics_per_ep(pred, true):\n",
    "    \"\"\"Compute (MAE, RAE, R2, Spearman, Kendall) for 1-D arrays.\"\"\"\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    rae = mae / np.mean(np.abs(true - np.mean(true)))\n",
    "    r2 = r2_score(true, pred) if np.nanstd(true) > 0 else np.nan\n",
    "    spr = spearmanr(true, pred).statistic\n",
    "    ktau = kendalltau(true, pred).statistic\n",
    "    return mae, rae, r2, spr, ktau\n",
    "\n",
    "\n",
    "def calculate_logd_metrics(pred, true, n_bootstrap_samples=1000):\n",
    "    \"\"\"Bootstrap evaluation for LogD. Returns dict of metric -> (mean, std).\"\"\"\n",
    "    metric_names = [\"MAE\", \"RAE\", \"R2\", \"Spearman R\", \"Kendall's Tau\"]\n",
    "    results = {m: [] for m in metric_names}\n",
    "\n",
    "    for indx in bootstrap_sampling(true.shape[0], n_bootstrap_samples):\n",
    "        vals = metrics_per_ep(pred[indx], true[indx])\n",
    "        for m, v in zip(metric_names, vals):\n",
    "            results[m].append(v)\n",
    "\n",
    "    summary = {}\n",
    "    for m in metric_names:\n",
    "        arr = np.array(results[m])\n",
    "        summary[m] = (float(np.nanmean(arr)), float(np.nanstd(arr)))\n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"Evaluation helpers loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Evaluate submission on LB / Private / All splits\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "gt_df = pd.read_csv(TEST_CSV)\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "gt_lb      = gt_df[gt_df[\"is_leaderboard\"] == 1].copy()\n",
    "gt_private = gt_df[gt_df[\"is_leaderboard\"] == 0].copy()\n",
    "gt_all     = gt_df.copy()\n",
    "\n",
    "print(f\"Split sizes \\u2014 LB: {len(gt_lb)}, Private: {len(gt_private)}, All: {len(gt_all)}\")\n",
    "print(\"Running bootstrap evaluation (1000 samples per split)...\\n\")\n",
    "\n",
    "splits = {\"LB\": gt_lb, \"Private\": gt_private, \"All\": gt_all}\n",
    "\n",
    "split_results = {}\n",
    "for split_name, gt_subset in splits.items():\n",
    "    merged = submission.merge(gt_subset, on=\"Molecule Name\", suffixes=(\"_pred\", \"_true\"))\n",
    "    pred = merged[\"LogD_pred\"].to_numpy()\n",
    "    true = merged[\"LogD_true\"].to_numpy()\n",
    "    mask = np.isfinite(pred) & np.isfinite(true)\n",
    "    pred, true = pred[mask], true[mask]\n",
    "    if len(pred) == 0:\n",
    "        print(f\"  {split_name}: no valid data\")\n",
    "        continue\n",
    "    split_results[split_name] = calculate_logd_metrics(pred, true)\n",
    "    print(f\"  {split_name}: {len(pred)} molecules evaluated\")\n",
    "\n",
    "# Print results\n",
    "metric_names = [\"MAE\", \"RAE\", \"R2\", \"Spearman R\", \"Kendall's Tau\"]\n",
    "for split_name in [\"LB\", \"Private\", \"All\"]:\n",
    "    if split_name not in split_results:\n",
    "        continue\n",
    "    sr = split_results[split_name]\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  {split_name} Split  (mean \\u00b1 bootstrap std, 1000 samples)\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    for m in metric_names:\n",
    "        mean, std = sr[m]\n",
    "        print(f\"  {m:<16s} {mean:.3f} \\u00b1 {std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Scatter plot: Predicted vs True LogD\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "gt_df = pd.read_csv(TEST_CSV)\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "merged = submission.merge(gt_df, on=\"Molecule Name\", suffixes=(\"_pred\", \"_true\"))\n",
    "subset = merged[[\"LogD_pred\", \"LogD_true\"]].dropna()\n",
    "y_pred = subset[\"LogD_pred\"].to_numpy()\n",
    "y_true = subset[\"LogD_true\"].to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(y_true, y_pred, alpha=0.3, s=10, color=\"steelblue\")\n",
    "\n",
    "# Diagonal reference line\n",
    "lo = min(y_true.min(), y_pred.min())\n",
    "hi = max(y_true.max(), y_pred.max())\n",
    "margin = (hi - lo) * 0.05\n",
    "ax.plot([lo - margin, hi + margin], [lo - margin, hi + margin],\n",
    "        \"r--\", alpha=0.7, lw=1)\n",
    "\n",
    "# R\\u00b2 annotation\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "ax.annotate(\n",
    "    f\"R\\u00b2 = {r2:.3f}\", xy=(0.05, 0.95), xycoords=\"axes fraction\",\n",
    "    fontsize=12, ha=\"left\", va=\"top\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"wheat\", alpha=0.5),\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"True LogD\")\n",
    "ax.set_ylabel(\"Predicted LogD\")\n",
    "ax.set_title(\"Predicted vs True LogD \\u2014 Test Set\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gt-pyg)",
   "language": "python",
   "name": "gt-pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
